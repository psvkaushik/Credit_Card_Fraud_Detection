{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6OVqeWju8Eni"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import PrecisionRecallDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import math\n",
        "import collections\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import keras.backend as K \n",
        "from tensorflow.python.ops import math_ops\n"
      ],
      "metadata": {
        "id": "JL5D-QLA9wo6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import glob\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Reshape\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.optimizers import SGD, Adam, RMSprop, Adagrad\n",
        "from keras.layers import Dropout, InputLayer, LSTM\n",
        "from keras.layers import Bidirectional, BatchNormalization\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout, UpSampling1D, AveragePooling1D\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, precision_recall_curve, precision_recall_fscore_support\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "ojDtkg9K913t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='prc',  patience = 5,verbose=1,factor=0.25,min_lr=0.0001)"
      ],
      "metadata": {
        "id": "3ROgE3v7-DZX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [ \n",
        "      #keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      #keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n"
      ],
      "metadata": {
        "id": "OEr-XIOp-XeE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_sampled=pd.read_csv('https://raw.githubusercontent.com/sushanthreddyC/Credit_Card_Fraud_Detection/main/data/X_train_sampled.csv')\n",
        "y_train_sampled=pd.read_csv('https://raw.githubusercontent.com/sushanthreddyC/Credit_Card_Fraud_Detection/main/data/y_train_sampled.csv')\n",
        "x_val=pd.read_csv('https://raw.githubusercontent.com/sushanthreddyC/Credit_Card_Fraud_Detection/main/data/X_val.csv')\n",
        "y_val=pd.read_csv('https://raw.githubusercontent.com/sushanthreddyC/Credit_Card_Fraud_Detection/main/data/y_val.csv')\n",
        "x_test=pd.read_csv('https://raw.githubusercontent.com/sushanthreddyC/Credit_Card_Fraud_Detection/main/data/X_test.csv')\n",
        "y_test=pd.read_csv('https://raw.githubusercontent.com/sushanthreddyC/Credit_Card_Fraud_Detection/main/data/y_test.csv')"
      ],
      "metadata": {
        "id": "YCw8qjBE8ndm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train_sampled.drop(columns=['Unnamed: 0'],axis=1)\n",
        "y_test = y_test.drop(columns=['Unnamed: 0'],axis=1)\n",
        "y_val = y_val.drop(columns=['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "ip9_Z3t7FIVw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = x_train_sampled.drop(columns=['Unnamed: 0'],axis=1)\n",
        "X_test = x_test.drop(columns=['Unnamed: 0'],axis=1)\n",
        "X_val = x_val.drop(columns=['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "e5akRZ2--jbW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar = StandardScaler().fit(X_train[['Amount']])\n",
        "X_train['norm_amount']=scalar.transform(X_train[['Amount']])\n",
        "X_val['norm_amount']=scalar.transform(X_val[['Amount']])\n",
        "X_test['norm_amount']=scalar.transform(X_test[['Amount']])"
      ],
      "metadata": {
        "id": "TFHHVAqoAG4L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm= X_train.drop(columns=['Amount'])\n",
        "X_val_norm=X_val.drop(columns=['Amount'])\n",
        "X_test_norm=X_test.drop(columns=['Amount'])"
      ],
      "metadata": {
        "id": "-36620h8Dflx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "PKweDEVXEy-w",
        "outputId": "c3093756-0d64-43cc-de26-05fec532a2c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             V1         V2         V3        V4         V5         V6  \\\n",
              "0     -0.776250   0.570153   1.415719  0.139392  -0.934473  -0.134084   \n",
              "1     -0.533484  -3.549124  -0.750384  0.225106  -1.974226  -0.733971   \n",
              "2     -4.055118  -2.855461  -5.498679  0.564467 -15.165565   8.535960   \n",
              "3     -2.053442  -0.640250  -0.259325 -1.955024  -1.373383   2.302825   \n",
              "4     -9.030538 -11.112584 -16.233798  3.592021 -40.427726  23.917837   \n",
              "...         ...        ...        ...       ...        ...        ...   \n",
              "64918  1.852889   1.069593  -1.776101  4.617410   0.770413  -0.400859   \n",
              "64919  0.842025  -0.365518  -2.464063  4.820886   0.775505  -0.614785   \n",
              "64920 -3.387601   3.977881  -6.978585  1.657766  -1.100500  -3.599487   \n",
              "64921 -1.464897   1.975528  -1.077145  2.819191   0.069850  -0.789044   \n",
              "64922 -6.498086   4.750515  -8.966558  7.098854  -6.958376  -2.822126   \n",
              "\n",
              "              V7        V8        V9        V10  ...       V20       V21  \\\n",
              "0      -0.225937  0.690748 -0.136626  -0.491977  ... -0.253557  0.349105   \n",
              "1       1.015846 -0.552599 -1.122843   0.186828  ...  1.598803  0.022444   \n",
              "2      15.126554 -2.831633 -0.143379  -2.933269  ... -3.794086 -1.773843   \n",
              "3       1.775314  0.188454  0.821384  -0.942763  ... -1.130299  0.056884   \n",
              "4      44.054461 -7.277778 -4.210637  -7.776435  ...  2.454553 -0.269048   \n",
              "...          ...       ...       ...        ...  ...       ...       ...   \n",
              "64918  -0.040970  0.089510 -0.217705  -0.373927  ... -0.288392 -0.157869   \n",
              "64919   1.368024 -0.526262 -0.121356  -0.357616  ...  0.944915 -0.110622   \n",
              "64920  -3.686651  1.942252 -3.065089  -7.509557  ... -0.004301  1.043587   \n",
              "64921  -1.196101  0.673654 -1.363724  -2.932895  ...  0.048969  0.174099   \n",
              "64922 -10.333406  4.031907 -6.648778 -11.634414  ...  0.568338  2.158143   \n",
              "\n",
              "            V22       V23       V24       V25       V26       V27       V28  \\\n",
              "0      0.844217  0.125810  0.381495 -0.531789  0.355948 -0.086168  0.011662   \n",
              "1     -1.722699 -0.698802  0.441908 -0.284432  0.708331 -0.244997  0.185745   \n",
              "2     -0.813322 -1.342666  0.342469 -1.532460  0.109184  3.076447 -2.089205   \n",
              "3      1.262423  0.306064 -1.532305 -0.594157  0.735095 -0.238998 -0.158877   \n",
              "4      0.988144  7.040028  0.347693  2.520869  2.342495  3.478175 -2.713136   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "64918 -0.176244  0.027437 -0.468006  0.058063  0.148263  0.042278  0.040573   \n",
              "64919 -1.257800 -0.324418 -0.420020 -0.219501 -0.268873 -0.144582  0.104464   \n",
              "64920  0.262189 -0.479224 -0.326638 -0.156939  0.113807  0.354124  0.287592   \n",
              "64921 -0.272505 -0.031549 -0.406166  0.157769 -0.104393  0.073796 -0.041570   \n",
              "64922  0.111510  0.216414  0.584661  0.760360  0.081972  1.415068  0.035124   \n",
              "\n",
              "       norm_amount  \n",
              "0        -0.329064  \n",
              "1         2.210274  \n",
              "2         8.829863  \n",
              "3         0.759243  \n",
              "4        26.597496  \n",
              "...            ...  \n",
              "64918    -0.458461  \n",
              "64919     1.054994  \n",
              "64920    -0.460106  \n",
              "64921    -0.458461  \n",
              "64922    -0.239911  \n",
              "\n",
              "[64923 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39f2cf15-221c-4f26-9fa1-92cfaf12ffb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>norm_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.776250</td>\n",
              "      <td>0.570153</td>\n",
              "      <td>1.415719</td>\n",
              "      <td>0.139392</td>\n",
              "      <td>-0.934473</td>\n",
              "      <td>-0.134084</td>\n",
              "      <td>-0.225937</td>\n",
              "      <td>0.690748</td>\n",
              "      <td>-0.136626</td>\n",
              "      <td>-0.491977</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.253557</td>\n",
              "      <td>0.349105</td>\n",
              "      <td>0.844217</td>\n",
              "      <td>0.125810</td>\n",
              "      <td>0.381495</td>\n",
              "      <td>-0.531789</td>\n",
              "      <td>0.355948</td>\n",
              "      <td>-0.086168</td>\n",
              "      <td>0.011662</td>\n",
              "      <td>-0.329064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.533484</td>\n",
              "      <td>-3.549124</td>\n",
              "      <td>-0.750384</td>\n",
              "      <td>0.225106</td>\n",
              "      <td>-1.974226</td>\n",
              "      <td>-0.733971</td>\n",
              "      <td>1.015846</td>\n",
              "      <td>-0.552599</td>\n",
              "      <td>-1.122843</td>\n",
              "      <td>0.186828</td>\n",
              "      <td>...</td>\n",
              "      <td>1.598803</td>\n",
              "      <td>0.022444</td>\n",
              "      <td>-1.722699</td>\n",
              "      <td>-0.698802</td>\n",
              "      <td>0.441908</td>\n",
              "      <td>-0.284432</td>\n",
              "      <td>0.708331</td>\n",
              "      <td>-0.244997</td>\n",
              "      <td>0.185745</td>\n",
              "      <td>2.210274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.055118</td>\n",
              "      <td>-2.855461</td>\n",
              "      <td>-5.498679</td>\n",
              "      <td>0.564467</td>\n",
              "      <td>-15.165565</td>\n",
              "      <td>8.535960</td>\n",
              "      <td>15.126554</td>\n",
              "      <td>-2.831633</td>\n",
              "      <td>-0.143379</td>\n",
              "      <td>-2.933269</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.794086</td>\n",
              "      <td>-1.773843</td>\n",
              "      <td>-0.813322</td>\n",
              "      <td>-1.342666</td>\n",
              "      <td>0.342469</td>\n",
              "      <td>-1.532460</td>\n",
              "      <td>0.109184</td>\n",
              "      <td>3.076447</td>\n",
              "      <td>-2.089205</td>\n",
              "      <td>8.829863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.053442</td>\n",
              "      <td>-0.640250</td>\n",
              "      <td>-0.259325</td>\n",
              "      <td>-1.955024</td>\n",
              "      <td>-1.373383</td>\n",
              "      <td>2.302825</td>\n",
              "      <td>1.775314</td>\n",
              "      <td>0.188454</td>\n",
              "      <td>0.821384</td>\n",
              "      <td>-0.942763</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.130299</td>\n",
              "      <td>0.056884</td>\n",
              "      <td>1.262423</td>\n",
              "      <td>0.306064</td>\n",
              "      <td>-1.532305</td>\n",
              "      <td>-0.594157</td>\n",
              "      <td>0.735095</td>\n",
              "      <td>-0.238998</td>\n",
              "      <td>-0.158877</td>\n",
              "      <td>0.759243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.030538</td>\n",
              "      <td>-11.112584</td>\n",
              "      <td>-16.233798</td>\n",
              "      <td>3.592021</td>\n",
              "      <td>-40.427726</td>\n",
              "      <td>23.917837</td>\n",
              "      <td>44.054461</td>\n",
              "      <td>-7.277778</td>\n",
              "      <td>-4.210637</td>\n",
              "      <td>-7.776435</td>\n",
              "      <td>...</td>\n",
              "      <td>2.454553</td>\n",
              "      <td>-0.269048</td>\n",
              "      <td>0.988144</td>\n",
              "      <td>7.040028</td>\n",
              "      <td>0.347693</td>\n",
              "      <td>2.520869</td>\n",
              "      <td>2.342495</td>\n",
              "      <td>3.478175</td>\n",
              "      <td>-2.713136</td>\n",
              "      <td>26.597496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64918</th>\n",
              "      <td>1.852889</td>\n",
              "      <td>1.069593</td>\n",
              "      <td>-1.776101</td>\n",
              "      <td>4.617410</td>\n",
              "      <td>0.770413</td>\n",
              "      <td>-0.400859</td>\n",
              "      <td>-0.040970</td>\n",
              "      <td>0.089510</td>\n",
              "      <td>-0.217705</td>\n",
              "      <td>-0.373927</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.288392</td>\n",
              "      <td>-0.157869</td>\n",
              "      <td>-0.176244</td>\n",
              "      <td>0.027437</td>\n",
              "      <td>-0.468006</td>\n",
              "      <td>0.058063</td>\n",
              "      <td>0.148263</td>\n",
              "      <td>0.042278</td>\n",
              "      <td>0.040573</td>\n",
              "      <td>-0.458461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64919</th>\n",
              "      <td>0.842025</td>\n",
              "      <td>-0.365518</td>\n",
              "      <td>-2.464063</td>\n",
              "      <td>4.820886</td>\n",
              "      <td>0.775505</td>\n",
              "      <td>-0.614785</td>\n",
              "      <td>1.368024</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-0.121356</td>\n",
              "      <td>-0.357616</td>\n",
              "      <td>...</td>\n",
              "      <td>0.944915</td>\n",
              "      <td>-0.110622</td>\n",
              "      <td>-1.257800</td>\n",
              "      <td>-0.324418</td>\n",
              "      <td>-0.420020</td>\n",
              "      <td>-0.219501</td>\n",
              "      <td>-0.268873</td>\n",
              "      <td>-0.144582</td>\n",
              "      <td>0.104464</td>\n",
              "      <td>1.054994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64920</th>\n",
              "      <td>-3.387601</td>\n",
              "      <td>3.977881</td>\n",
              "      <td>-6.978585</td>\n",
              "      <td>1.657766</td>\n",
              "      <td>-1.100500</td>\n",
              "      <td>-3.599487</td>\n",
              "      <td>-3.686651</td>\n",
              "      <td>1.942252</td>\n",
              "      <td>-3.065089</td>\n",
              "      <td>-7.509557</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004301</td>\n",
              "      <td>1.043587</td>\n",
              "      <td>0.262189</td>\n",
              "      <td>-0.479224</td>\n",
              "      <td>-0.326638</td>\n",
              "      <td>-0.156939</td>\n",
              "      <td>0.113807</td>\n",
              "      <td>0.354124</td>\n",
              "      <td>0.287592</td>\n",
              "      <td>-0.460106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64921</th>\n",
              "      <td>-1.464897</td>\n",
              "      <td>1.975528</td>\n",
              "      <td>-1.077145</td>\n",
              "      <td>2.819191</td>\n",
              "      <td>0.069850</td>\n",
              "      <td>-0.789044</td>\n",
              "      <td>-1.196101</td>\n",
              "      <td>0.673654</td>\n",
              "      <td>-1.363724</td>\n",
              "      <td>-2.932895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048969</td>\n",
              "      <td>0.174099</td>\n",
              "      <td>-0.272505</td>\n",
              "      <td>-0.031549</td>\n",
              "      <td>-0.406166</td>\n",
              "      <td>0.157769</td>\n",
              "      <td>-0.104393</td>\n",
              "      <td>0.073796</td>\n",
              "      <td>-0.041570</td>\n",
              "      <td>-0.458461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64922</th>\n",
              "      <td>-6.498086</td>\n",
              "      <td>4.750515</td>\n",
              "      <td>-8.966558</td>\n",
              "      <td>7.098854</td>\n",
              "      <td>-6.958376</td>\n",
              "      <td>-2.822126</td>\n",
              "      <td>-10.333406</td>\n",
              "      <td>4.031907</td>\n",
              "      <td>-6.648778</td>\n",
              "      <td>-11.634414</td>\n",
              "      <td>...</td>\n",
              "      <td>0.568338</td>\n",
              "      <td>2.158143</td>\n",
              "      <td>0.111510</td>\n",
              "      <td>0.216414</td>\n",
              "      <td>0.584661</td>\n",
              "      <td>0.760360</td>\n",
              "      <td>0.081972</td>\n",
              "      <td>1.415068</td>\n",
              "      <td>0.035124</td>\n",
              "      <td>-0.239911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64923 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f2cf15-221c-4f26-9fa1-92cfaf12ffb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39f2cf15-221c-4f26-9fa1-92cfaf12ffb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39f2cf15-221c-4f26-9fa1-92cfaf12ffb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DNN"
      ],
      "metadata": {
        "id": "TofGjBITI_ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dnn():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_dim=X_train_norm.shape[-1]))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer=RMSprop(),loss='binary_crossentropy',metrics=METRICS)\n",
        "  return model "
      ],
      "metadata": {
        "id": "DyOvmd789GcS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=0.1\n",
        "dnn_model=create_dnn()\n",
        "dnn_model.summary()\n",
        "dnn_model.fit(X_train_norm,y_train, batch_size=512, epochs=85, verbose =1, validation_data=(X_val_norm,y_val), class_weight={0: 0.3**2, 1: (1-0.3)**2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te54SM4y-Kl4",
        "outputId": "be4ec8c5-dc07-4c9d-d27c-c0051e40ba74"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 32)                960       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 993\n",
            "Trainable params: 993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/85\n",
            "127/127 [==============================] - 2s 9ms/step - loss: 0.0293 - precision: 0.0362 - recall: 0.5570 - prc: 0.2151 - val_loss: 0.1137 - val_precision: 0.8214 - val_recall: 0.7302 - val_prc: 0.6327\n",
            "Epoch 2/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0064 - precision: 0.8741 - recall: 0.7307 - prc: 0.7010 - val_loss: 0.0243 - val_precision: 0.8065 - val_recall: 0.7937 - val_prc: 0.6792\n",
            "Epoch 3/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0039 - precision: 0.8625 - recall: 0.7771 - prc: 0.7309 - val_loss: 0.0122 - val_precision: 0.8095 - val_recall: 0.8095 - val_prc: 0.7131\n",
            "Epoch 4/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0033 - precision: 0.8523 - recall: 0.7864 - prc: 0.7594 - val_loss: 0.0086 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7312\n",
            "Epoch 5/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0030 - precision: 0.8492 - recall: 0.8019 - prc: 0.7688 - val_loss: 0.0069 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7388\n",
            "Epoch 6/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0028 - precision: 0.8529 - recall: 0.8080 - prc: 0.7803 - val_loss: 0.0061 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7402\n",
            "Epoch 7/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0028 - precision: 0.8280 - recall: 0.8050 - prc: 0.7827 - val_loss: 0.0059 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7382\n",
            "Epoch 8/85\n",
            "127/127 [==============================] - 2s 12ms/step - loss: 0.0026 - precision: 0.8156 - recall: 0.8080 - prc: 0.7860 - val_loss: 0.0056 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7390\n",
            "Epoch 9/85\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0025 - precision: 0.8276 - recall: 0.8173 - prc: 0.7931 - val_loss: 0.0053 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7433\n",
            "Epoch 10/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0025 - precision: 0.8255 - recall: 0.8204 - prc: 0.7980 - val_loss: 0.0055 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7414\n",
            "Epoch 11/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0024 - precision: 0.8135 - recall: 0.8235 - prc: 0.7935 - val_loss: 0.0049 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7439\n",
            "Epoch 12/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0024 - precision: 0.8146 - recall: 0.8297 - prc: 0.7969 - val_loss: 0.0049 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.7557\n",
            "Epoch 13/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0023 - precision: 0.8297 - recall: 0.8297 - prc: 0.8138 - val_loss: 0.0047 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7573\n",
            "Epoch 14/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0023 - precision: 0.8036 - recall: 0.8235 - prc: 0.8013 - val_loss: 0.0049 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7564\n",
            "Epoch 15/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0024 - precision: 0.8127 - recall: 0.8328 - prc: 0.7974 - val_loss: 0.0049 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.7570\n",
            "Epoch 16/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0022 - precision: 0.8375 - recall: 0.8297 - prc: 0.8099 - val_loss: 0.0048 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7588\n",
            "Epoch 17/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0023 - precision: 0.8065 - recall: 0.8390 - prc: 0.8027 - val_loss: 0.0045 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7704\n",
            "Epoch 18/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0023 - precision: 0.8036 - recall: 0.8235 - prc: 0.8165 - val_loss: 0.0043 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7729\n",
            "Epoch 19/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0023 - precision: 0.8215 - recall: 0.8266 - prc: 0.8081 - val_loss: 0.0039 - val_precision: 0.7812 - val_recall: 0.7937 - val_prc: 0.7687\n",
            "Epoch 20/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0023 - precision: 0.8204 - recall: 0.8204 - prc: 0.8072 - val_loss: 0.0043 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7742\n",
            "Epoch 21/85\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.0022 - precision: 0.8176 - recall: 0.8328 - prc: 0.8235 - val_loss: 0.0041 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7741\n",
            "Epoch 22/85\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0022 - precision: 0.8242 - recall: 0.8421 - prc: 0.8252 - val_loss: 0.0042 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7776\n",
            "Epoch 23/85\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0022 - precision: 0.8262 - recall: 0.8390 - prc: 0.8181 - val_loss: 0.0042 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7737\n",
            "Epoch 24/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0022 - precision: 0.8313 - recall: 0.8390 - prc: 0.8236 - val_loss: 0.0041 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.7727\n",
            "Epoch 25/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0021 - precision: 0.8328 - recall: 0.8328 - prc: 0.8191 - val_loss: 0.0042 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7761\n",
            "Epoch 26/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0021 - precision: 0.8257 - recall: 0.8359 - prc: 0.8214 - val_loss: 0.0042 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7783\n",
            "Epoch 27/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0021 - precision: 0.8047 - recall: 0.8421 - prc: 0.8336 - val_loss: 0.0041 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7773\n",
            "Epoch 28/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0020 - precision: 0.8157 - recall: 0.8359 - prc: 0.8313 - val_loss: 0.0043 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7765\n",
            "Epoch 29/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0020 - precision: 0.8119 - recall: 0.8421 - prc: 0.8284 - val_loss: 0.0043 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7766\n",
            "Epoch 30/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0020 - precision: 0.8198 - recall: 0.8452 - prc: 0.8323 - val_loss: 0.0039 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.7719\n",
            "Epoch 31/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0021 - precision: 0.8354 - recall: 0.8328 - prc: 0.8311 - val_loss: 0.0041 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7725\n",
            "Epoch 32/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0021 - precision: 0.8293 - recall: 0.8421 - prc: 0.8303 - val_loss: 0.0043 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7756\n",
            "Epoch 33/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.8029 - recall: 0.8452 - prc: 0.8348 - val_loss: 0.0041 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7732\n",
            "Epoch 34/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0020 - precision: 0.8374 - recall: 0.8452 - prc: 0.8420 - val_loss: 0.0042 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7600\n",
            "Epoch 35/85\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0020 - precision: 0.8102 - recall: 0.8328 - prc: 0.8414 - val_loss: 0.0043 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7757\n",
            "Epoch 36/85\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.0020 - precision: 0.8168 - recall: 0.8421 - prc: 0.8443 - val_loss: 0.0044 - val_precision: 0.6986 - val_recall: 0.8095 - val_prc: 0.7788\n",
            "Epoch 37/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0020 - precision: 0.7936 - recall: 0.8452 - prc: 0.8288 - val_loss: 0.0039 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7750\n",
            "Epoch 38/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.8287 - recall: 0.8390 - prc: 0.8460 - val_loss: 0.0041 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7785\n",
            "Epoch 39/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.7942 - recall: 0.8483 - prc: 0.8502 - val_loss: 0.0041 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7704\n",
            "Epoch 40/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.8035 - recall: 0.8483 - prc: 0.8526 - val_loss: 0.0041 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7709\n",
            "Epoch 41/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.8095 - recall: 0.8421 - prc: 0.8544 - val_loss: 0.0039 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7825\n",
            "Epoch 42/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0020 - precision: 0.7890 - recall: 0.8452 - prc: 0.8443 - val_loss: 0.0041 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7655\n",
            "Epoch 43/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.8308 - recall: 0.8514 - prc: 0.8494 - val_loss: 0.0039 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7681\n",
            "Epoch 44/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.8131 - recall: 0.8483 - prc: 0.8542 - val_loss: 0.0040 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7668\n",
            "Epoch 45/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.8071 - recall: 0.8421 - prc: 0.8516 - val_loss: 0.0039 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7692\n",
            "Epoch 46/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.8318 - recall: 0.8421 - prc: 0.8598 - val_loss: 0.0039 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7718\n",
            "Epoch 47/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.8328 - recall: 0.8483 - prc: 0.8542 - val_loss: 0.0043 - val_precision: 0.6842 - val_recall: 0.8254 - val_prc: 0.7704\n",
            "Epoch 48/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.8040 - recall: 0.8638 - prc: 0.8615 - val_loss: 0.0039 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7691\n",
            "Epoch 49/85\n",
            "127/127 [==============================] - 1s 12ms/step - loss: 0.0019 - precision: 0.8338 - recall: 0.8545 - prc: 0.8579 - val_loss: 0.0042 - val_precision: 0.6753 - val_recall: 0.8254 - val_prc: 0.7525\n",
            "Epoch 50/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0020 - precision: 0.8070 - recall: 0.8545 - prc: 0.8504 - val_loss: 0.0041 - val_precision: 0.7222 - val_recall: 0.8254 - val_prc: 0.7673\n",
            "Epoch 51/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.7819 - recall: 0.8545 - prc: 0.8555 - val_loss: 0.0038 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7657\n",
            "Epoch 52/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0018 - precision: 0.8065 - recall: 0.8514 - prc: 0.8546 - val_loss: 0.0039 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7665\n",
            "Epoch 53/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.8035 - recall: 0.8483 - prc: 0.8605 - val_loss: 0.0037 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7671\n",
            "Epoch 54/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0018 - precision: 0.8136 - recall: 0.8514 - prc: 0.8619 - val_loss: 0.0040 - val_precision: 0.7123 - val_recall: 0.8254 - val_prc: 0.7244\n",
            "Epoch 55/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.8166 - recall: 0.8545 - prc: 0.8519 - val_loss: 0.0040 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7509\n",
            "Epoch 56/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.8147 - recall: 0.8576 - prc: 0.8572 - val_loss: 0.0042 - val_precision: 0.7027 - val_recall: 0.8254 - val_prc: 0.7426\n",
            "Epoch 57/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.7787 - recall: 0.8607 - prc: 0.8630 - val_loss: 0.0038 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7704\n",
            "Epoch 58/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0018 - precision: 0.8087 - recall: 0.8638 - prc: 0.8605 - val_loss: 0.0038 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7687\n",
            "Epoch 59/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0018 - precision: 0.8195 - recall: 0.8576 - prc: 0.8537 - val_loss: 0.0039 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7672\n",
            "Epoch 60/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.8163 - recall: 0.8669 - prc: 0.8607 - val_loss: 0.0037 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.7815\n",
            "Epoch 61/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.8234 - recall: 0.8514 - prc: 0.8652 - val_loss: 0.0041 - val_precision: 0.7123 - val_recall: 0.8254 - val_prc: 0.7565\n",
            "Epoch 62/85\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 0.0019 - precision: 0.8076 - recall: 0.8576 - prc: 0.8533 - val_loss: 0.0043 - val_precision: 0.6625 - val_recall: 0.8413 - val_prc: 0.7820\n",
            "Epoch 63/85\n",
            "127/127 [==============================] - 1s 9ms/step - loss: 0.0018 - precision: 0.7932 - recall: 0.8669 - prc: 0.8662 - val_loss: 0.0036 - val_precision: 0.7727 - val_recall: 0.8095 - val_prc: 0.7275\n",
            "Epoch 64/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.8176 - recall: 0.8607 - prc: 0.8623 - val_loss: 0.0039 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.7280\n",
            "Epoch 65/85\n",
            "127/127 [==============================] - 1s 10ms/step - loss: 0.0016 - precision: 0.8274 - recall: 0.8607 - prc: 0.8784 - val_loss: 0.0040 - val_precision: 0.6753 - val_recall: 0.8254 - val_prc: 0.7514\n",
            "Epoch 66/85\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.0018 - precision: 0.8187 - recall: 0.8669 - prc: 0.8754 - val_loss: 0.0039 - val_precision: 0.6986 - val_recall: 0.8095 - val_prc: 0.7833\n",
            "Epoch 67/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0017 - precision: 0.8254 - recall: 0.8638 - prc: 0.8799 - val_loss: 0.0037 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7710\n",
            "Epoch 68/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0018 - precision: 0.8220 - recall: 0.8576 - prc: 0.8725 - val_loss: 0.0038 - val_precision: 0.6933 - val_recall: 0.8254 - val_prc: 0.7835\n",
            "Epoch 69/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0017 - precision: 0.7919 - recall: 0.8483 - prc: 0.8793 - val_loss: 0.0037 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7540\n",
            "Epoch 70/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.7790 - recall: 0.8514 - prc: 0.8679 - val_loss: 0.0036 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7625\n",
            "Epoch 71/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0019 - precision: 0.8023 - recall: 0.8545 - prc: 0.8699 - val_loss: 0.0039 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7293\n",
            "Epoch 72/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0017 - precision: 0.8309 - recall: 0.8669 - prc: 0.8799 - val_loss: 0.0039 - val_precision: 0.6986 - val_recall: 0.8095 - val_prc: 0.7484\n",
            "Epoch 73/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0017 - precision: 0.8129 - recall: 0.8607 - prc: 0.8740 - val_loss: 0.0036 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7972\n",
            "Epoch 74/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0016 - precision: 0.8092 - recall: 0.8669 - prc: 0.8831 - val_loss: 0.0035 - val_precision: 0.7500 - val_recall: 0.8095 - val_prc: 0.8011\n",
            "Epoch 75/85\n",
            "127/127 [==============================] - 1s 11ms/step - loss: 0.0018 - precision: 0.8179 - recall: 0.8483 - prc: 0.8685 - val_loss: 0.0036 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7998\n",
            "Epoch 76/85\n",
            "127/127 [==============================] - 1s 8ms/step - loss: 0.0017 - precision: 0.7966 - recall: 0.8607 - prc: 0.8692 - val_loss: 0.0037 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7675\n",
            "Epoch 77/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0018 - precision: 0.7829 - recall: 0.8483 - prc: 0.8595 - val_loss: 0.0038 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7564\n",
            "Epoch 78/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0018 - precision: 0.7709 - recall: 0.8545 - prc: 0.8648 - val_loss: 0.0035 - val_precision: 0.7727 - val_recall: 0.8095 - val_prc: 0.7821\n",
            "Epoch 79/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0016 - precision: 0.8075 - recall: 0.8700 - prc: 0.8896 - val_loss: 0.0038 - val_precision: 0.6986 - val_recall: 0.8095 - val_prc: 0.8033\n",
            "Epoch 80/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0017 - precision: 0.7949 - recall: 0.8638 - prc: 0.8774 - val_loss: 0.0037 - val_precision: 0.7222 - val_recall: 0.8254 - val_prc: 0.8035\n",
            "Epoch 81/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0019 - precision: 0.7654 - recall: 0.8483 - prc: 0.8621 - val_loss: 0.0037 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7706\n",
            "Epoch 82/85\n",
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0016 - precision: 0.8017 - recall: 0.8638 - prc: 0.8804 - val_loss: 0.0037 - val_precision: 0.7612 - val_recall: 0.8095 - val_prc: 0.7695\n",
            "Epoch 83/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0017 - precision: 0.8080 - recall: 0.8731 - prc: 0.8706 - val_loss: 0.0037 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7865\n",
            "Epoch 84/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0016 - precision: 0.7581 - recall: 0.8731 - prc: 0.8815 - val_loss: 0.0036 - val_precision: 0.7391 - val_recall: 0.8095 - val_prc: 0.7851\n",
            "Epoch 85/85\n",
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0016 - precision: 0.8152 - recall: 0.8607 - prc: 0.8794 - val_loss: 0.0034 - val_precision: 0.7727 - val_recall: 0.8095 - val_prc: 0.7883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefa81e6a30>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_test_preds= dnn_model.predict(X_test_norm)\n",
        "dense_val_preds = dnn_model.predict(X_val_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RK035eJE8Gq",
        "outputId": "d449c61f-5d38-40cc-9a3e-77050ba81823"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1774/1774 [==============================] - 3s 1ms/step\n",
            "1419/1419 [==============================] - 2s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dense_test_preds>0.5).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R96b7T8pFbVs",
        "outputId": "b434e60c-e58c-457c-b1be-d76816dce6e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    56659\n",
              "True        87\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = keras.metrics.AUC(name='prc', curve='PR')\n",
        "m.update_state(y_val, dense_val_preds)\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg8gNs4tFet3",
        "outputId": "5c2547e5-926b-45ad-a818-8329bcacab51"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.78832316"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = keras.metrics.AUC(name='prc', curve='PR')\n",
        "m.update_state(y_test, dense_test_preds)\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AKgJOCZFhXI",
        "outputId": "d79fd266-5d7b-46bc-8e72-0b7acc036145"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77571845"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, dense_test_preds>0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHFFJXbbFjcr",
        "outputId": "a883ad47-59a0-4e09-eb6d-da601a5ebaba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56659\n",
            "           1       0.79      0.79      0.79        87\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.90      0.90      0.90     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PrecisionRecallDisplay.from_predictions(y_test, dense_test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "BNtZrqvQMgc8",
        "outputId": "72a102fa-d6a0-48f2-9f84-e78c5f60ed0e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7fefa87df1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN"
      ],
      "metadata": {
        "id": "cTmWBnS7IBbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn():\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv1D(256, 2, activation='relu', padding ='valid', input_shape=(X_train_norm.shape[-1],1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # model.add(Conv1D(256, 2, activation='relu', padding ='valid', input_shape=(X_train_norm.shape[-1],1)))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  #model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop',loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=METRICS)\n",
        "  return model"
      ],
      "metadata": {
        "id": "qqwxzN9ZFm_4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn=create_cnn()\n",
        "cnn.summary()\n",
        "cnn.fit(X_train_norm,y_train, batch_size=512, epochs=50, verbose=2, validation_data=(X_val_norm,y_val), class_weight={0: 0.35**2, 1: (1-0.35)**2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QofUSZYIR0M",
        "outputId": "cbdb5be1-60d7-4bf5-a2f8-cd36689174c4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 28, 256)           768       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 256)          1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 28, 256)           0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 7168)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 7169      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,961\n",
            "Trainable params: 8,449\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n",
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127/127 - 4s - loss: 0.0062 - precision: 0.4564 - recall: 0.8005 - prc: 0.6785 - val_loss: 0.1869 - val_precision: 0.8136 - val_recall: 0.7619 - val_prc: 0.6790 - 4s/epoch - 29ms/step\n",
            "Epoch 2/50\n",
            "127/127 - 1s - loss: 0.0046 - precision: 0.7213 - recall: 0.7771 - prc: 0.7147 - val_loss: 0.0693 - val_precision: 0.7692 - val_recall: 0.7937 - val_prc: 0.7139 - 1s/epoch - 8ms/step\n",
            "Epoch 3/50\n",
            "127/127 - 1s - loss: 0.0041 - precision: 0.7530 - recall: 0.7833 - prc: 0.7149 - val_loss: 0.0185 - val_precision: 0.7812 - val_recall: 0.7937 - val_prc: 0.7352 - 1s/epoch - 8ms/step\n",
            "Epoch 4/50\n",
            "127/127 - 1s - loss: 0.0041 - precision: 0.7262 - recall: 0.7802 - prc: 0.7382 - val_loss: 0.0103 - val_precision: 0.7353 - val_recall: 0.7937 - val_prc: 0.6793 - 1s/epoch - 8ms/step\n",
            "Epoch 5/50\n",
            "127/127 - 1s - loss: 0.0035 - precision: 0.7364 - recall: 0.7957 - prc: 0.7491 - val_loss: 0.0069 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7312 - 1s/epoch - 8ms/step\n",
            "Epoch 6/50\n",
            "127/127 - 1s - loss: 0.0037 - precision: 0.7567 - recall: 0.7895 - prc: 0.7416 - val_loss: 0.0044 - val_precision: 0.9730 - val_recall: 0.5714 - val_prc: 0.7086 - 1s/epoch - 9ms/step\n",
            "Epoch 7/50\n",
            "127/127 - 1s - loss: 0.0033 - precision: 0.7442 - recall: 0.7926 - prc: 0.7452 - val_loss: 0.0073 - val_precision: 0.7692 - val_recall: 0.7937 - val_prc: 0.7165 - 1s/epoch - 8ms/step\n",
            "Epoch 8/50\n",
            "127/127 - 1s - loss: 0.0032 - precision: 0.7626 - recall: 0.7957 - prc: 0.7592 - val_loss: 0.0053 - val_precision: 0.8065 - val_recall: 0.7937 - val_prc: 0.7228 - 1s/epoch - 8ms/step\n",
            "Epoch 9/50\n",
            "127/127 - 1s - loss: 0.0033 - precision: 0.7808 - recall: 0.8050 - prc: 0.7736 - val_loss: 0.0086 - val_precision: 0.7353 - val_recall: 0.7937 - val_prc: 0.7105 - 1s/epoch - 8ms/step\n",
            "Epoch 10/50\n",
            "127/127 - 1s - loss: 0.0034 - precision: 0.7692 - recall: 0.8050 - prc: 0.7698 - val_loss: 0.0053 - val_precision: 0.8596 - val_recall: 0.7778 - val_prc: 0.7072 - 1s/epoch - 8ms/step\n",
            "Epoch 11/50\n",
            "127/127 - 2s - loss: 0.0032 - precision: 0.7679 - recall: 0.7988 - prc: 0.7665 - val_loss: 0.0133 - val_precision: 0.3706 - val_recall: 0.8413 - val_prc: 0.6363 - 2s/epoch - 12ms/step\n",
            "Epoch 12/50\n",
            "127/127 - 1s - loss: 0.0031 - precision: 0.7471 - recall: 0.7957 - prc: 0.7621 - val_loss: 0.0064 - val_precision: 0.8654 - val_recall: 0.7143 - val_prc: 0.7184 - 1s/epoch - 9ms/step\n",
            "Epoch 13/50\n",
            "127/127 - 1s - loss: 0.0031 - precision: 0.7719 - recall: 0.8173 - prc: 0.7822 - val_loss: 0.0042 - val_precision: 0.8305 - val_recall: 0.7778 - val_prc: 0.7057 - 1s/epoch - 9ms/step\n",
            "Epoch 14/50\n",
            "127/127 - 1s - loss: 0.0030 - precision: 0.7885 - recall: 0.8080 - prc: 0.7822 - val_loss: 0.0073 - val_precision: 0.8529 - val_recall: 0.4603 - val_prc: 0.5208 - 1s/epoch - 8ms/step\n",
            "Epoch 15/50\n",
            "127/127 - 1s - loss: 0.0029 - precision: 0.7771 - recall: 0.7988 - prc: 0.7843 - val_loss: 0.0047 - val_precision: 0.7273 - val_recall: 0.7619 - val_prc: 0.7958 - 1s/epoch - 8ms/step\n",
            "Epoch 16/50\n",
            "127/127 - 1s - loss: 0.0031 - precision: 0.7715 - recall: 0.8050 - prc: 0.7749 - val_loss: 0.0057 - val_precision: 0.7143 - val_recall: 0.7937 - val_prc: 0.7318 - 1s/epoch - 9ms/step\n",
            "Epoch 17/50\n",
            "127/127 - 1s - loss: 0.0030 - precision: 0.7550 - recall: 0.8111 - prc: 0.7739 - val_loss: 0.0061 - val_precision: 0.7183 - val_recall: 0.8095 - val_prc: 0.7392 - 1s/epoch - 8ms/step\n",
            "Epoch 18/50\n",
            "127/127 - 1s - loss: 0.0031 - precision: 0.8012 - recall: 0.8111 - prc: 0.7983 - val_loss: 0.0048 - val_precision: 0.6154 - val_recall: 0.7619 - val_prc: 0.7117 - 1s/epoch - 9ms/step\n",
            "Epoch 19/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.7825 - recall: 0.8019 - prc: 0.7846 - val_loss: 0.0079 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7246 - 1s/epoch - 9ms/step\n",
            "Epoch 20/50\n",
            "127/127 - 1s - loss: 0.0033 - precision: 0.7663 - recall: 0.8019 - prc: 0.7744 - val_loss: 0.0093 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.7126 - 1s/epoch - 9ms/step\n",
            "Epoch 21/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.7784 - recall: 0.8050 - prc: 0.7932 - val_loss: 0.0119 - val_precision: 0.6220 - val_recall: 0.8095 - val_prc: 0.6846 - 1s/epoch - 9ms/step\n",
            "Epoch 22/50\n",
            "127/127 - 1s - loss: 0.0031 - precision: 0.7507 - recall: 0.7926 - prc: 0.7601 - val_loss: 0.0080 - val_precision: 0.7937 - val_recall: 0.7937 - val_prc: 0.7205 - 1s/epoch - 10ms/step\n",
            "Epoch 23/50\n",
            "127/127 - 1s - loss: 0.0030 - precision: 0.7821 - recall: 0.8111 - prc: 0.7830 - val_loss: 0.0101 - val_precision: 0.7286 - val_recall: 0.8095 - val_prc: 0.6979 - 1s/epoch - 10ms/step\n",
            "Epoch 24/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.8100 - recall: 0.8050 - prc: 0.7900 - val_loss: 0.0084 - val_precision: 0.4636 - val_recall: 0.8095 - val_prc: 0.7178 - 1s/epoch - 9ms/step\n",
            "Epoch 25/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.7543 - recall: 0.8173 - prc: 0.7906 - val_loss: 0.0053 - val_precision: 0.7778 - val_recall: 0.7778 - val_prc: 0.7432 - 1s/epoch - 9ms/step\n",
            "Epoch 26/50\n",
            "127/127 - 1s - loss: 0.0028 - precision: 0.7764 - recall: 0.7957 - prc: 0.7808 - val_loss: 0.0062 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7262 - 1s/epoch - 9ms/step\n",
            "Epoch 27/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.7952 - recall: 0.8173 - prc: 0.7993 - val_loss: 0.0082 - val_precision: 0.5667 - val_recall: 0.8095 - val_prc: 0.6815 - 1s/epoch - 9ms/step\n",
            "Epoch 28/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.8037 - recall: 0.8111 - prc: 0.7997 - val_loss: 0.0032 - val_precision: 0.8421 - val_recall: 0.7619 - val_prc: 0.7793 - 1s/epoch - 8ms/step\n",
            "Epoch 29/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.7885 - recall: 0.8080 - prc: 0.7859 - val_loss: 0.0056 - val_precision: 0.7937 - val_recall: 0.7937 - val_prc: 0.7188 - 1s/epoch - 8ms/step\n",
            "Epoch 30/50\n",
            "127/127 - 1s - loss: 0.0028 - precision: 0.7715 - recall: 0.8050 - prc: 0.7810 - val_loss: 0.0104 - val_precision: 0.6047 - val_recall: 0.8254 - val_prc: 0.6669 - 1s/epoch - 8ms/step\n",
            "Epoch 31/50\n",
            "127/127 - 1s - loss: 0.0030 - precision: 0.7784 - recall: 0.8050 - prc: 0.7650 - val_loss: 0.0050 - val_precision: 0.8136 - val_recall: 0.7619 - val_prc: 0.7038 - 1s/epoch - 8ms/step\n",
            "Epoch 32/50\n",
            "127/127 - 1s - loss: 0.0025 - precision: 0.7887 - recall: 0.8204 - prc: 0.7964 - val_loss: 0.0071 - val_precision: 0.5747 - val_recall: 0.7937 - val_prc: 0.7284 - 1s/epoch - 12ms/step\n",
            "Epoch 33/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.8043 - recall: 0.8142 - prc: 0.7968 - val_loss: 0.0038 - val_precision: 0.7656 - val_recall: 0.7778 - val_prc: 0.7295 - 1s/epoch - 10ms/step\n",
            "Epoch 34/50\n",
            "127/127 - 1s - loss: 0.0025 - precision: 0.7774 - recall: 0.8111 - prc: 0.8036 - val_loss: 0.0063 - val_precision: 0.8033 - val_recall: 0.7778 - val_prc: 0.6959 - 1s/epoch - 9ms/step\n",
            "Epoch 35/50\n",
            "127/127 - 1s - loss: 0.0025 - precision: 0.8043 - recall: 0.8142 - prc: 0.8154 - val_loss: 0.0041 - val_precision: 0.7692 - val_recall: 0.7937 - val_prc: 0.7286 - 1s/epoch - 9ms/step\n",
            "Epoch 36/50\n",
            "127/127 - 1s - loss: 0.0025 - precision: 0.7994 - recall: 0.8266 - prc: 0.8172 - val_loss: 0.0079 - val_precision: 0.7846 - val_recall: 0.8095 - val_prc: 0.7279 - 1s/epoch - 8ms/step\n",
            "Epoch 37/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.8062 - recall: 0.7988 - prc: 0.7975 - val_loss: 0.0048 - val_precision: 0.8421 - val_recall: 0.7619 - val_prc: 0.7545 - 1s/epoch - 8ms/step\n",
            "Epoch 38/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.8043 - recall: 0.8142 - prc: 0.8004 - val_loss: 0.0125 - val_precision: 0.4435 - val_recall: 0.8730 - val_prc: 0.6753 - 1s/epoch - 9ms/step\n",
            "Epoch 39/50\n",
            "127/127 - 1s - loss: 0.0024 - precision: 0.8012 - recall: 0.8235 - prc: 0.8185 - val_loss: 0.0074 - val_precision: 0.7083 - val_recall: 0.8095 - val_prc: 0.7221 - 1s/epoch - 8ms/step\n",
            "Epoch 40/50\n",
            "127/127 - 1s - loss: 0.0024 - precision: 0.8043 - recall: 0.8142 - prc: 0.8169 - val_loss: 0.0085 - val_precision: 0.7727 - val_recall: 0.8095 - val_prc: 0.7132 - 1s/epoch - 9ms/step\n",
            "Epoch 41/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.7801 - recall: 0.8019 - prc: 0.8054 - val_loss: 0.0073 - val_precision: 0.7937 - val_recall: 0.7937 - val_prc: 0.7019 - 1s/epoch - 9ms/step\n",
            "Epoch 42/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.8173 - recall: 0.8173 - prc: 0.8034 - val_loss: 0.0096 - val_precision: 0.5909 - val_recall: 0.8254 - val_prc: 0.6937 - 1s/epoch - 8ms/step\n",
            "Epoch 43/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.8006 - recall: 0.8204 - prc: 0.8090 - val_loss: 0.0065 - val_precision: 0.7647 - val_recall: 0.6190 - val_prc: 0.6262 - 1s/epoch - 10ms/step\n",
            "Epoch 44/50\n",
            "127/127 - 1s - loss: 0.0027 - precision: 0.7988 - recall: 0.8111 - prc: 0.7970 - val_loss: 0.0059 - val_precision: 0.7869 - val_recall: 0.7619 - val_prc: 0.7269 - 1s/epoch - 10ms/step\n",
            "Epoch 45/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.7818 - recall: 0.7988 - prc: 0.7824 - val_loss: 0.0060 - val_precision: 0.7538 - val_recall: 0.7778 - val_prc: 0.7764 - 1s/epoch - 9ms/step\n",
            "Epoch 46/50\n",
            "127/127 - 1s - loss: 0.0026 - precision: 0.8193 - recall: 0.8142 - prc: 0.7961 - val_loss: 0.0061 - val_precision: 0.7101 - val_recall: 0.7778 - val_prc: 0.7284 - 1s/epoch - 8ms/step\n",
            "Epoch 47/50\n",
            "127/127 - 1s - loss: 0.0024 - precision: 0.8043 - recall: 0.8142 - prc: 0.8054 - val_loss: 0.0047 - val_precision: 0.7538 - val_recall: 0.7778 - val_prc: 0.7415 - 1s/epoch - 9ms/step\n",
            "Epoch 48/50\n",
            "127/127 - 1s - loss: 0.0024 - precision: 0.8127 - recall: 0.8328 - prc: 0.8281 - val_loss: 0.0078 - val_precision: 0.6753 - val_recall: 0.8254 - val_prc: 0.7489 - 1s/epoch - 9ms/step\n",
            "Epoch 49/50\n",
            "127/127 - 1s - loss: 0.0024 - precision: 0.7834 - recall: 0.8173 - prc: 0.8136 - val_loss: 0.0061 - val_precision: 0.7424 - val_recall: 0.7778 - val_prc: 0.7381 - 1s/epoch - 8ms/step\n",
            "Epoch 50/50\n",
            "127/127 - 1s - loss: 0.0025 - precision: 0.8406 - recall: 0.8328 - prc: 0.8273 - val_loss: 0.0051 - val_precision: 0.7576 - val_recall: 0.7937 - val_prc: 0.7146 - 1s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef96fadcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_test_preds= cnn.predict(X_test_norm)\n",
        "cnn_val_preds = cnn.predict(X_val_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZTFsIIuIXp1",
        "outputId": "da2d54c7-b26c-4953-c533-e79ef1d87691"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1774/1774 [==============================] - 3s 2ms/step\n",
            "1419/1419 [==============================] - 2s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m=keras.metrics.AUC(name='prc', curve='PR')\n",
        "m.update_state(y_test, cnn_test_preds)\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTC4LDs-JNzp",
        "outputId": "a30470c2-9d13-400b-8e93-692e48bfdb60"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73245907"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m=keras.metrics.AUC(name='prc', curve='PR')\n",
        "m.update_state(y_val, cnn_val_preds)\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRydsiW_Jw3E",
        "outputId": "a06f4f1b-306e-4847-a0b5-ecebf05e5c78"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7145642"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "PrecisionRecallDisplay.from_predictions(y_test, cnn_test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "7sMSxVaeMPUL",
        "outputId": "35b3a749-1244-44cb-e110-562c0c3a5db1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7fef96f341c0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, cnn_test_preds>0.5))"
      ],
      "metadata": {
        "id": "WFjHSB2cMZH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5b3b75-ac1c-4500-9f9f-8f3c182bb244"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56659\n",
            "           1       0.77      0.80      0.79        87\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.88      0.90      0.89     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FS"
      ],
      "metadata": {
        "id": "mdnfsHzhcMIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[[ 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9','V10', 'Amount']]\n",
        "X_test = x_test[[ 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9','V10', 'Amount']]\n",
        "X_val = x_val[[ 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9','V10', 'Amount']]"
      ],
      "metadata": {
        "id": "rF-qsaJvcK7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RMIBbyGNcbrn",
        "outputId": "1e2f6fb2-6fbf-4a49-ab5f-a08f63eb048d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             V1         V2         V3        V4         V5         V6  \\\n",
              "0     -0.776250   0.570153   1.415719  0.139392  -0.934473  -0.134084   \n",
              "1     -0.533484  -3.549124  -0.750384  0.225106  -1.974226  -0.733971   \n",
              "2     -4.055118  -2.855461  -5.498679  0.564467 -15.165565   8.535960   \n",
              "3     -2.053442  -0.640250  -0.259325 -1.955024  -1.373383   2.302825   \n",
              "4     -9.030538 -11.112584 -16.233798  3.592021 -40.427726  23.917837   \n",
              "...         ...        ...        ...       ...        ...        ...   \n",
              "64918  1.852889   1.069593  -1.776101  4.617410   0.770413  -0.400859   \n",
              "64919  0.842025  -0.365518  -2.464063  4.820886   0.775505  -0.614785   \n",
              "64920 -3.387601   3.977881  -6.978585  1.657766  -1.100500  -3.599487   \n",
              "64921 -1.464897   1.975528  -1.077145  2.819191   0.069850  -0.789044   \n",
              "64922 -6.498086   4.750515  -8.966558  7.098854  -6.958376  -2.822126   \n",
              "\n",
              "              V7        V8        V9        V10     Amount  \n",
              "0      -0.225937  0.690748 -0.136626  -0.491977     49.775  \n",
              "1       1.015846 -0.552599 -1.122843   0.186828   1006.950  \n",
              "2      15.126554 -2.831633 -0.143379  -2.933269   3502.130  \n",
              "3       1.775314  0.188454  0.821384  -0.942763    460.000  \n",
              "4      44.054461 -7.277778 -4.210637  -7.776435  10199.440  \n",
              "...          ...       ...       ...        ...        ...  \n",
              "64918  -0.040970  0.089510 -0.217705  -0.373927      1.000  \n",
              "64919   1.368024 -0.526262 -0.121356  -0.357616    571.480  \n",
              "64920  -3.686651  1.942252 -3.065089  -7.509557      0.380  \n",
              "64921  -1.196101  0.673654 -1.363724  -2.932895      1.000  \n",
              "64922 -10.333406  4.031907 -6.648778 -11.634414     83.380  \n",
              "\n",
              "[64923 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63b2ce6c-2a64-4d26-a0fa-1ab36cdd9f86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.776250</td>\n",
              "      <td>0.570153</td>\n",
              "      <td>1.415719</td>\n",
              "      <td>0.139392</td>\n",
              "      <td>-0.934473</td>\n",
              "      <td>-0.134084</td>\n",
              "      <td>-0.225937</td>\n",
              "      <td>0.690748</td>\n",
              "      <td>-0.136626</td>\n",
              "      <td>-0.491977</td>\n",
              "      <td>49.775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.533484</td>\n",
              "      <td>-3.549124</td>\n",
              "      <td>-0.750384</td>\n",
              "      <td>0.225106</td>\n",
              "      <td>-1.974226</td>\n",
              "      <td>-0.733971</td>\n",
              "      <td>1.015846</td>\n",
              "      <td>-0.552599</td>\n",
              "      <td>-1.122843</td>\n",
              "      <td>0.186828</td>\n",
              "      <td>1006.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.055118</td>\n",
              "      <td>-2.855461</td>\n",
              "      <td>-5.498679</td>\n",
              "      <td>0.564467</td>\n",
              "      <td>-15.165565</td>\n",
              "      <td>8.535960</td>\n",
              "      <td>15.126554</td>\n",
              "      <td>-2.831633</td>\n",
              "      <td>-0.143379</td>\n",
              "      <td>-2.933269</td>\n",
              "      <td>3502.130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.053442</td>\n",
              "      <td>-0.640250</td>\n",
              "      <td>-0.259325</td>\n",
              "      <td>-1.955024</td>\n",
              "      <td>-1.373383</td>\n",
              "      <td>2.302825</td>\n",
              "      <td>1.775314</td>\n",
              "      <td>0.188454</td>\n",
              "      <td>0.821384</td>\n",
              "      <td>-0.942763</td>\n",
              "      <td>460.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.030538</td>\n",
              "      <td>-11.112584</td>\n",
              "      <td>-16.233798</td>\n",
              "      <td>3.592021</td>\n",
              "      <td>-40.427726</td>\n",
              "      <td>23.917837</td>\n",
              "      <td>44.054461</td>\n",
              "      <td>-7.277778</td>\n",
              "      <td>-4.210637</td>\n",
              "      <td>-7.776435</td>\n",
              "      <td>10199.440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64918</th>\n",
              "      <td>1.852889</td>\n",
              "      <td>1.069593</td>\n",
              "      <td>-1.776101</td>\n",
              "      <td>4.617410</td>\n",
              "      <td>0.770413</td>\n",
              "      <td>-0.400859</td>\n",
              "      <td>-0.040970</td>\n",
              "      <td>0.089510</td>\n",
              "      <td>-0.217705</td>\n",
              "      <td>-0.373927</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64919</th>\n",
              "      <td>0.842025</td>\n",
              "      <td>-0.365518</td>\n",
              "      <td>-2.464063</td>\n",
              "      <td>4.820886</td>\n",
              "      <td>0.775505</td>\n",
              "      <td>-0.614785</td>\n",
              "      <td>1.368024</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-0.121356</td>\n",
              "      <td>-0.357616</td>\n",
              "      <td>571.480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64920</th>\n",
              "      <td>-3.387601</td>\n",
              "      <td>3.977881</td>\n",
              "      <td>-6.978585</td>\n",
              "      <td>1.657766</td>\n",
              "      <td>-1.100500</td>\n",
              "      <td>-3.599487</td>\n",
              "      <td>-3.686651</td>\n",
              "      <td>1.942252</td>\n",
              "      <td>-3.065089</td>\n",
              "      <td>-7.509557</td>\n",
              "      <td>0.380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64921</th>\n",
              "      <td>-1.464897</td>\n",
              "      <td>1.975528</td>\n",
              "      <td>-1.077145</td>\n",
              "      <td>2.819191</td>\n",
              "      <td>0.069850</td>\n",
              "      <td>-0.789044</td>\n",
              "      <td>-1.196101</td>\n",
              "      <td>0.673654</td>\n",
              "      <td>-1.363724</td>\n",
              "      <td>-2.932895</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64922</th>\n",
              "      <td>-6.498086</td>\n",
              "      <td>4.750515</td>\n",
              "      <td>-8.966558</td>\n",
              "      <td>7.098854</td>\n",
              "      <td>-6.958376</td>\n",
              "      <td>-2.822126</td>\n",
              "      <td>-10.333406</td>\n",
              "      <td>4.031907</td>\n",
              "      <td>-6.648778</td>\n",
              "      <td>-11.634414</td>\n",
              "      <td>83.380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64923 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63b2ce6c-2a64-4d26-a0fa-1ab36cdd9f86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63b2ce6c-2a64-4d26-a0fa-1ab36cdd9f86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63b2ce6c-2a64-4d26-a0fa-1ab36cdd9f86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar = StandardScaler().fit(X_train[['Amount']])\n",
        "X_train['norm_amount']=scalar.transform(X_train[['Amount']])\n",
        "X_val['norm_amount']=scalar.transform(X_val[['Amount']])\n",
        "X_test['norm_amount']=scalar.transform(X_test[['Amount']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMN9h4cXlOgq",
        "outputId": "cbdce094-ea78-4b37-eae7-2081c51cdb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e26afdcc33ac>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_val['norm_amount']=scalar.transform(X_val[['Amount']])\n",
            "<ipython-input-12-e26afdcc33ac>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test['norm_amount']=scalar.transform(X_test[['Amount']])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "OEIablxglhDx",
        "outputId": "cac82b17-e028-473d-812c-d9082bcf26df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             V1         V2         V3        V4         V5         V6  \\\n",
              "0     -0.776250   0.570153   1.415719  0.139392  -0.934473  -0.134084   \n",
              "1     -0.533484  -3.549124  -0.750384  0.225106  -1.974226  -0.733971   \n",
              "2     -4.055118  -2.855461  -5.498679  0.564467 -15.165565   8.535960   \n",
              "3     -2.053442  -0.640250  -0.259325 -1.955024  -1.373383   2.302825   \n",
              "4     -9.030538 -11.112584 -16.233798  3.592021 -40.427726  23.917837   \n",
              "...         ...        ...        ...       ...        ...        ...   \n",
              "64918  1.852889   1.069593  -1.776101  4.617410   0.770413  -0.400859   \n",
              "64919  0.842025  -0.365518  -2.464063  4.820886   0.775505  -0.614785   \n",
              "64920 -3.387601   3.977881  -6.978585  1.657766  -1.100500  -3.599487   \n",
              "64921 -1.464897   1.975528  -1.077145  2.819191   0.069850  -0.789044   \n",
              "64922 -6.498086   4.750515  -8.966558  7.098854  -6.958376  -2.822126   \n",
              "\n",
              "              V7        V8        V9        V10     Amount  norm_amount  \n",
              "0      -0.225937  0.690748 -0.136626  -0.491977     49.775    -0.329064  \n",
              "1       1.015846 -0.552599 -1.122843   0.186828   1006.950     2.210274  \n",
              "2      15.126554 -2.831633 -0.143379  -2.933269   3502.130     8.829863  \n",
              "3       1.775314  0.188454  0.821384  -0.942763    460.000     0.759243  \n",
              "4      44.054461 -7.277778 -4.210637  -7.776435  10199.440    26.597496  \n",
              "...          ...       ...       ...        ...        ...          ...  \n",
              "64918  -0.040970  0.089510 -0.217705  -0.373927      1.000    -0.458461  \n",
              "64919   1.368024 -0.526262 -0.121356  -0.357616    571.480     1.054994  \n",
              "64920  -3.686651  1.942252 -3.065089  -7.509557      0.380    -0.460106  \n",
              "64921  -1.196101  0.673654 -1.363724  -2.932895      1.000    -0.458461  \n",
              "64922 -10.333406  4.031907 -6.648778 -11.634414     83.380    -0.239911  \n",
              "\n",
              "[64923 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d45c7013-59fa-4e44-a394-c7e04fe6cf78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>Amount</th>\n",
              "      <th>norm_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.776250</td>\n",
              "      <td>0.570153</td>\n",
              "      <td>1.415719</td>\n",
              "      <td>0.139392</td>\n",
              "      <td>-0.934473</td>\n",
              "      <td>-0.134084</td>\n",
              "      <td>-0.225937</td>\n",
              "      <td>0.690748</td>\n",
              "      <td>-0.136626</td>\n",
              "      <td>-0.491977</td>\n",
              "      <td>49.775</td>\n",
              "      <td>-0.329064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.533484</td>\n",
              "      <td>-3.549124</td>\n",
              "      <td>-0.750384</td>\n",
              "      <td>0.225106</td>\n",
              "      <td>-1.974226</td>\n",
              "      <td>-0.733971</td>\n",
              "      <td>1.015846</td>\n",
              "      <td>-0.552599</td>\n",
              "      <td>-1.122843</td>\n",
              "      <td>0.186828</td>\n",
              "      <td>1006.950</td>\n",
              "      <td>2.210274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.055118</td>\n",
              "      <td>-2.855461</td>\n",
              "      <td>-5.498679</td>\n",
              "      <td>0.564467</td>\n",
              "      <td>-15.165565</td>\n",
              "      <td>8.535960</td>\n",
              "      <td>15.126554</td>\n",
              "      <td>-2.831633</td>\n",
              "      <td>-0.143379</td>\n",
              "      <td>-2.933269</td>\n",
              "      <td>3502.130</td>\n",
              "      <td>8.829863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.053442</td>\n",
              "      <td>-0.640250</td>\n",
              "      <td>-0.259325</td>\n",
              "      <td>-1.955024</td>\n",
              "      <td>-1.373383</td>\n",
              "      <td>2.302825</td>\n",
              "      <td>1.775314</td>\n",
              "      <td>0.188454</td>\n",
              "      <td>0.821384</td>\n",
              "      <td>-0.942763</td>\n",
              "      <td>460.000</td>\n",
              "      <td>0.759243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.030538</td>\n",
              "      <td>-11.112584</td>\n",
              "      <td>-16.233798</td>\n",
              "      <td>3.592021</td>\n",
              "      <td>-40.427726</td>\n",
              "      <td>23.917837</td>\n",
              "      <td>44.054461</td>\n",
              "      <td>-7.277778</td>\n",
              "      <td>-4.210637</td>\n",
              "      <td>-7.776435</td>\n",
              "      <td>10199.440</td>\n",
              "      <td>26.597496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64918</th>\n",
              "      <td>1.852889</td>\n",
              "      <td>1.069593</td>\n",
              "      <td>-1.776101</td>\n",
              "      <td>4.617410</td>\n",
              "      <td>0.770413</td>\n",
              "      <td>-0.400859</td>\n",
              "      <td>-0.040970</td>\n",
              "      <td>0.089510</td>\n",
              "      <td>-0.217705</td>\n",
              "      <td>-0.373927</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.458461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64919</th>\n",
              "      <td>0.842025</td>\n",
              "      <td>-0.365518</td>\n",
              "      <td>-2.464063</td>\n",
              "      <td>4.820886</td>\n",
              "      <td>0.775505</td>\n",
              "      <td>-0.614785</td>\n",
              "      <td>1.368024</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-0.121356</td>\n",
              "      <td>-0.357616</td>\n",
              "      <td>571.480</td>\n",
              "      <td>1.054994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64920</th>\n",
              "      <td>-3.387601</td>\n",
              "      <td>3.977881</td>\n",
              "      <td>-6.978585</td>\n",
              "      <td>1.657766</td>\n",
              "      <td>-1.100500</td>\n",
              "      <td>-3.599487</td>\n",
              "      <td>-3.686651</td>\n",
              "      <td>1.942252</td>\n",
              "      <td>-3.065089</td>\n",
              "      <td>-7.509557</td>\n",
              "      <td>0.380</td>\n",
              "      <td>-0.460106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64921</th>\n",
              "      <td>-1.464897</td>\n",
              "      <td>1.975528</td>\n",
              "      <td>-1.077145</td>\n",
              "      <td>2.819191</td>\n",
              "      <td>0.069850</td>\n",
              "      <td>-0.789044</td>\n",
              "      <td>-1.196101</td>\n",
              "      <td>0.673654</td>\n",
              "      <td>-1.363724</td>\n",
              "      <td>-2.932895</td>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.458461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64922</th>\n",
              "      <td>-6.498086</td>\n",
              "      <td>4.750515</td>\n",
              "      <td>-8.966558</td>\n",
              "      <td>7.098854</td>\n",
              "      <td>-6.958376</td>\n",
              "      <td>-2.822126</td>\n",
              "      <td>-10.333406</td>\n",
              "      <td>4.031907</td>\n",
              "      <td>-6.648778</td>\n",
              "      <td>-11.634414</td>\n",
              "      <td>83.380</td>\n",
              "      <td>-0.239911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64923 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d45c7013-59fa-4e44-a394-c7e04fe6cf78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d45c7013-59fa-4e44-a394-c7e04fe6cf78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d45c7013-59fa-4e44-a394-c7e04fe6cf78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zaxxICmVlkRY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}